{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Semantic Segmentation Using HAGDAVS Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:33:59.095509Z",
     "iopub.status.busy": "2023-06-29T15:33:59.095152Z",
     "iopub.status.idle": "2023-06-29T15:35:31.500614Z",
     "shell.execute_reply": "2023-06-29T15:35:31.499337Z",
     "shell.execute_reply.started": "2023-06-29T15:33:59.095480Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip uninstall tensorflow -y\n",
    "!pip uninstall tensorflow-io -y\n",
    "!pip uninstall tf-nightly -y\n",
    "!pip install tensorflow\n",
    "!pip install --no-deps tensorflow-io\n",
    "!pip install -U albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:37:04.190155Z",
     "iopub.status.busy": "2023-06-29T15:37:04.189484Z",
     "iopub.status.idle": "2023-06-29T15:37:11.811340Z",
     "shell.execute_reply": "2023-06-29T15:37:11.810404Z",
     "shell.execute_reply.started": "2023-06-29T15:37:04.190064Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pathlib\n",
    "from PIL import Image\n",
    "import shutil\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "from tensorflow.data import AUTOTUNE\n",
    "import albumentations as A\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the following actions:\n",
    "\n",
    "1. Defines directory paths for the input data, including the folder containing RGB images and the folder containing masks.\n",
    "2. Sets the destination folder path to save the modified images.\n",
    "3. Creates the new destination folder if it doesn't exist.\n",
    "4. Retrieves the list of file names in the masks folder.\n",
    "5. Iterates over each file in the list and does the following:\n",
    "   - Checks if the file name contains the text \"MClass\".\n",
    "   - If it does, modifies the file name by replacing \"MClass\" with \"RGB\".\n",
    "   - Creates an old file path and a new file path.\n",
    "   - Copies the old file to the new path.\n",
    "\n",
    "In summary, the code takes masks in the \"MClass\" format and copies them to a new folder, but changes their names to the \"RGB\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:37:25.073746Z",
     "iopub.status.busy": "2023-06-29T15:37:25.073285Z",
     "iopub.status.idle": "2023-06-29T15:37:30.674958Z",
     "shell.execute_reply": "2023-06-29T15:37:30.673925Z",
     "shell.execute_reply.started": "2023-06-29T15:37:25.073707Z"
    }
   },
   "outputs": [],
   "source": [
    "data_dir = pathlib.Path('/kaggle/input/hagdavs/HAGDAVS')\n",
    "images_dir = data_dir / 'RGB'\n",
    "masks_dir = data_dir / 'MASK'\n",
    "\n",
    "folder_path = masks_dir  # Ruta de la carpeta que contiene las imágenes\n",
    "new_folder_path = '/kaggle/working/semantic-segmentation-hagdavs/HAGDAVS/MASK'\n",
    "\n",
    "# Crear la nueva carpeta si no existe\n",
    "os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "# Obtener la lista de nombres de archivo en la carpeta\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Aplicar la modificación del nombre y crear nuevos archivos en la nueva carpeta\n",
    "for filename in file_list:\n",
    "    if \"MClass\" in filename:\n",
    "        new_filename = filename.replace(\"MClass\", \"RGB\")\n",
    "        old_path = os.path.join(folder_path, filename)\n",
    "        new_path = os.path.join(new_folder_path, new_filename)\n",
    "        shutil.copy2(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code performs the following actions:\n",
    "\n",
    "1. Defines directory paths for the image and mask folders.\n",
    "2. Retrieves a list of file paths for the images and masks.\n",
    "3. Creates empty lists to store image and mask patches.\n",
    "4. Sets the desired patch size.\n",
    "5. Defines a function to load and split the images and masks into patches.\n",
    "   - It reads the image and mask files.\n",
    "   - Removes the alpha channel from the images and masks.\n",
    "   - Divides the image into patches based on the specified patch size.\n",
    "   - Checks if all pixels in a mask patch are black, and if so, skips it.\n",
    "   - Appends the image and mask patches to their respective lists.\n",
    "6. Applies the load_and_split_patches function to each image and mask pair.\n",
    "7. Converts the lists of patches into TensorFlow tensors.\n",
    "8. Creates a dataset from the image and mask patches.\n",
    "\n",
    "In summary, the code loads image and mask files, divides them into patches of a specified size, filters out patches with all-black masks, and creates a dataset for further processing or training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:38:20.228291Z",
     "iopub.status.busy": "2023-06-29T15:38:20.227928Z",
     "iopub.status.idle": "2023-06-29T15:38:51.639001Z",
     "shell.execute_reply": "2023-06-29T15:38:51.637914Z",
     "shell.execute_reply.started": "2023-06-29T15:38:20.228262Z"
    }
   },
   "outputs": [],
   "source": [
    "# Ruta a las carpetas de imágenes y máscaras\n",
    "ima_dir = pathlib.Path('/kaggle/input/hagdavs/HAGDAVS')\n",
    "images_dir = ima_dir / 'RGB'\n",
    "m_dir = pathlib.Path('/kaggle/working/semantic-segmentation-hagdavs/HAGDAVS')\n",
    "mask_dir = m_dir / 'MASK'\n",
    "\n",
    "# Obtener una lista de rutas de archivo para imágenes y máscaras\n",
    "image_paths = sorted([str(path) for path in images_dir.glob('*.tif')])\n",
    "mask_paths = sorted([str(path) for path in mask_dir.glob('*.tif')])\n",
    "\n",
    "# Crear una lista para almacenar los parches de imágenes y máscaras\n",
    "image_patches = []\n",
    "mask_patches = []\n",
    "\n",
    "# Tamaño del parche deseado\n",
    "patch_size = (256, 256)\n",
    "\n",
    "\n",
    "# Definir una función para cargar y dividir las imágenes y máscaras en parches\n",
    "def load_and_split_patches(image_path, mask_path):\n",
    "    # Con los Paths, coge las imagenes como tensores (array)\n",
    "    image = tfio.experimental.image.decode_tiff(tf.io.read_file(image_path))\n",
    "    mask = tfio.experimental.image.decode_tiff(tf.io.read_file(mask_path))\n",
    "\n",
    "    # Eliminar el canal alfa de las imágenes y máscaras\n",
    "    image = image[:, :, :3] / 255\n",
    "    mask = mask[:, :, :3]\n",
    "\n",
    "    # Dividir la imagen en parches\n",
    "    for i in range(0, image.shape[0], patch_size[0]):\n",
    "        for j in range(0, image.shape[1], patch_size[1]):\n",
    "            patch_image = image[i:i+patch_size[0], j:j+patch_size[1], :]\n",
    "            patch_mask = mask[i:i+patch_size[0], j:j+patch_size[1], :]\n",
    "\n",
    "            # Verificar si todos los píxeles en el parche de la máscara son negros\n",
    "            if tf.reduce_all(tf.math.equal(patch_mask, [0, 0, 0])):\n",
    "                continue\n",
    "                \n",
    "            #patch_mask = convertir_colores(patch_mask)\n",
    "            image_patches.append(patch_image)\n",
    "            mask_patches.append(patch_mask)\n",
    "\n",
    "    return None\n",
    "\n",
    "# Aplicar la función de carga y división de parches a cada par de rutas de archivo\n",
    "for image_path, mask_path in zip(image_paths, mask_paths):\n",
    "    load_and_split_patches(image_path, mask_path)\n",
    "\n",
    "# Convertir las listas de parches en tensores\n",
    "image_patches = tf.convert_to_tensor(image_patches)\n",
    "mask_patches = tf.convert_to_tensor(mask_patches)\n",
    "\n",
    "# Crear un dataset a partir de los parches de imágenes y máscaras\n",
    "dataset = tf.data.Dataset.from_tensor_slices((image_patches, mask_patches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of images in dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:38:57.689280Z",
     "iopub.status.busy": "2023-06-29T15:38:57.688617Z",
     "iopub.status.idle": "2023-06-29T15:38:57.695990Z",
     "shell.execute_reply": "2023-06-29T15:38:57.695146Z",
     "shell.execute_reply.started": "2023-06-29T15:38:57.689244Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Display Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for show the image, mask and prediction mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:39:09.505183Z",
     "iopub.status.busy": "2023-06-29T15:39:09.504816Z",
     "iopub.status.idle": "2023-06-29T15:39:09.511832Z",
     "shell.execute_reply": "2023-06-29T15:39:09.510691Z",
     "shell.execute_reply.started": "2023-06-29T15:39:09.505155Z"
    }
   },
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = [\"Input Image\", \"True Mask\", \"Predicted Mask\"]\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "    plt.axis(\"off\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using only one class**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function called `convertir_mascara` and applies it to a dataset using the `map` function.\n",
    "\n",
    "The `convertir_mascara` function performs the following actions:\n",
    "\n",
    "1. Casts the input mask tensor to `float32` data type.\n",
    "2. Creates a new mask tensor filled with zeros, with dimensions `(256, 256, 1)`.\n",
    "3. Assigns values corresponding to each class in the mask:\n",
    "   - If all RGB values in the mask are `[0, 0, 0]`, assigns `0.0` to the corresponding pixel in the converted mask.\n",
    "   - If all RGB values are `[255, 0, 0]`, assigns `0.0`.\n",
    "   - If all RGB values are `[0, 255, 0]`, assigns `1.0`.\n",
    "   - If all RGB values are `[0, 0, 255]`, assigns `0.0`.\n",
    "4. Returns the converted mask.\n",
    "\n",
    "The code then applies the `convertir_mascara` function to each element in the `dataset` using the `map` function. The `map` function takes a lambda function that applies the conversion function to each `(image, mask)` pair in the dataset, resulting in a new dataset named `mapped_dataset`. The images in the dataset remain unchanged, while the masks are converted using the `convertir_mascara` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:39:12.811610Z",
     "iopub.status.busy": "2023-06-29T15:39:12.811263Z",
     "iopub.status.idle": "2023-06-29T15:39:13.004221Z",
     "shell.execute_reply": "2023-06-29T15:39:13.003244Z",
     "shell.execute_reply.started": "2023-06-29T15:39:12.811583Z"
    }
   },
   "outputs": [],
   "source": [
    "def convertir_mascara(mascara):\n",
    "    mascara = tf.cast(mascara, dtype=tf.float32)\n",
    "    mascara_convertida = tf.zeros((256, 256, 1), dtype=tf.float32)\n",
    "\n",
    "    # Asigna valores correspondientes a cada clase\n",
    "    mascara_convertida = tf.where(tf.reduce_all(tf.equal(mascara, [0, 0, 0]), axis=-1, keepdims=True), 0.0, mascara_convertida)\n",
    "    mascara_convertida = tf.where(tf.reduce_all(tf.equal(mascara, [255, 0, 0]), axis=-1, keepdims=True), 0.0, mascara_convertida)\n",
    "    mascara_convertida = tf.where(tf.reduce_all(tf.equal(mascara, [0, 255, 0]), axis=-1, keepdims=True), 1.0, mascara_convertida)\n",
    "    mascara_convertida = tf.where(tf.reduce_all(tf.equal(mascara, [0, 0, 255]), axis=-1, keepdims=True), 0.0, mascara_convertida)\n",
    "\n",
    "    return mascara_convertida\n",
    "\n",
    "mapped_dataset = dataset.map(lambda x, y: (x, convertir_mascara(y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code defines a function called `filter_func` that filters the `mapped_dataset` based on certain criteria using the `filter` function.\n",
    "\n",
    "The `filter_func` function performs the following actions:\n",
    "\n",
    "1. Reshapes the mask tensor into a 1-dimensional tensor.\n",
    "2. Uses `tf.unique` to obtain the unique classes present in the mask.\n",
    "3. Checks if the number of unique classes (`tf.size(unique_classes)`) is greater than or equal to 2.\n",
    "   - If there are two or more unique classes, it returns `True`, indicating that the image and mask pair should be included in the filtered dataset.\n",
    "   - If there are fewer than two unique classes, it returns `False`, indicating that the image and mask pair should be filtered out.\n",
    "\n",
    "The code then applies the `filter_func` function to each element in the `mapped_dataset` using the `filter` function. The `filter` function takes the lambda function `filter_func` as an argument and returns a new dataset named `filtered_dataset` that contains only the image and mask pairs that satisfy the filtering criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:39:16.744071Z",
     "iopub.status.busy": "2023-06-29T15:39:16.743698Z",
     "iopub.status.idle": "2023-06-29T15:39:27.838353Z",
     "shell.execute_reply": "2023-06-29T15:39:27.836318Z",
     "shell.execute_reply.started": "2023-06-29T15:39:16.744041Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_func(image, mask):\n",
    "    unique_classes = tf.unique(tf.reshape(mask, [-1]))[0]\n",
    "    return tf.size(unique_classes) >= 2\n",
    "\n",
    "filtered_dataset = mapped_dataset.filter(filter_func)\n",
    "\n",
    "dataset_length = 0\n",
    "for _ in filtered_dataset:\n",
    "    dataset_length += 1\n",
    "\n",
    "print(\"Longitud aproximada del dataset filtrado:\", dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:39:39.042162Z",
     "iopub.status.busy": "2023-06-29T15:39:39.041128Z",
     "iopub.status.idle": "2023-06-29T15:39:39.050455Z",
     "shell.execute_reply": "2023-06-29T15:39:39.049361Z",
     "shell.execute_reply.started": "2023-06-29T15:39:39.042117Z"
    }
   },
   "outputs": [],
   "source": [
    "filtered_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:39:54.436537Z",
     "iopub.status.busy": "2023-06-29T15:39:54.436016Z",
     "iopub.status.idle": "2023-06-29T15:40:27.301255Z",
     "shell.execute_reply": "2023-06-29T15:40:27.300277Z",
     "shell.execute_reply.started": "2023-06-29T15:39:54.436495Z"
    }
   },
   "outputs": [],
   "source": [
    "# Secuencia de data augmentation\n",
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "])\n",
    "\n",
    "# Creo las imagenes aumentadas y las agrego a augmented_dataset\n",
    "c=0\n",
    "for image, mask in filtered_dataset:\n",
    "    \n",
    "    transformed = transform(image=image.numpy(), mask=mask.numpy())\n",
    "    \n",
    "    # Convertir los arrays a tensores de TensorFlow\n",
    "    tensor1 = tf.convert_to_tensor(transformed['image'], dtype=tf.float32)\n",
    "    tensor2 = tf.convert_to_tensor(transformed['mask'], dtype=tf.float32)\n",
    "\n",
    "    tensor1 = tf.expand_dims(tensor1, axis=0)  # Agregar una dimensión al inicio\n",
    "    tensor2 = tf.expand_dims(tensor2, axis=0)  # Agregar una dimensión al inicio\n",
    "\n",
    "    # Crear un nuevo dataset con ambos tensores\n",
    "    new_dataset = tf.data.Dataset.from_tensor_slices((tensor1, tensor2))\n",
    "    \n",
    "    if c==0:\n",
    "        augmented_dataset = new_dataset\n",
    "        c=1\n",
    "    else:\n",
    "        # Concatenar el dataset original con el nuevo dataset\n",
    "        augmented_dataset = augmented_dataset.concatenate(new_dataset)\n",
    "    \n",
    "# Agrego augmented_dataset a filtered_dataset\n",
    "filtered_dataset = filtered_dataset.concatenate(augmented_dataset)\n",
    "\n",
    "# Tamaño final de filtered_dataset\n",
    "dataset_length = 0\n",
    "for _ in filtered_dataset:\n",
    "    dataset_length += 1\n",
    "\n",
    "print(\"Longitud aproximada del dataset filtrado:\", dataset_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:40:35.220784Z",
     "iopub.status.busy": "2023-06-29T15:40:35.220405Z",
     "iopub.status.idle": "2023-06-29T15:40:38.371247Z",
     "shell.execute_reply": "2023-06-29T15:40:38.370242Z",
     "shell.execute_reply.started": "2023-06-29T15:40:35.220754Z"
    }
   },
   "outputs": [],
   "source": [
    "# Iterar sobre el dataset y mostrar los primeros 3 pares de imágenes y máscaras\n",
    "count = 0  # Contador de pares de imágenes y máscaras\n",
    "for image, mask in augmented_dataset:\n",
    "    # Mostrar la imagen\n",
    "    plt.subplot(1, 2, 1)  # Configurar el subplot para la imagen\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')  # Eliminar los ejes\n",
    "    plt.title('Imagen')\n",
    "\n",
    "    # Mostrar la máscara\n",
    "    plt.subplot(1, 2, 2)  # Configurar el subplot para la máscara\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')  # Eliminar los ejes\n",
    "    plt.title('Máscara')\n",
    "\n",
    "    plt.show()  # Mostrar la figura\n",
    "\n",
    "    count += 1  # Incrementar el contador\n",
    "    if count == 2:  # Salir del bucle después de 3 iteraciones\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Splitting data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train/test/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:40:43.044776Z",
     "iopub.status.busy": "2023-06-29T15:40:43.044415Z",
     "iopub.status.idle": "2023-06-29T15:40:43.069055Z",
     "shell.execute_reply": "2023-06-29T15:40:43.067943Z",
     "shell.execute_reply.started": "2023-06-29T15:40:43.044740Z"
    }
   },
   "outputs": [],
   "source": [
    "# dividir el dataset en conjuntos de entrenamiento, validación y prueba\n",
    "total_samples = (dataset_length)\n",
    "train_size = int(0.7 * total_samples)\n",
    "val_size = int(0.15 * total_samples)\n",
    "test_size = total_samples - train_size - val_size\n",
    "\n",
    "train_dataset = filtered_dataset.take(train_size)\n",
    "val_dataset = filtered_dataset.skip(train_size).take(val_size)\n",
    "test_dataset = filtered_dataset.skip(train_size + val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:40:44.826062Z",
     "iopub.status.busy": "2023-06-29T15:40:44.825691Z",
     "iopub.status.idle": "2023-06-29T15:40:44.833315Z",
     "shell.execute_reply": "2023-06-29T15:40:44.832260Z",
     "shell.execute_reply.started": "2023-06-29T15:40:44.826032Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T15:40:46.897333Z",
     "iopub.status.busy": "2023-06-29T15:40:46.896971Z",
     "iopub.status.idle": "2023-06-29T15:40:46.920948Z",
     "shell.execute_reply": "2023-06-29T15:40:46.920082Z",
     "shell.execute_reply.started": "2023-06-29T15:40:46.897304Z"
    }
   },
   "outputs": [],
   "source": [
    "train_batches = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_batches = train_batches.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "validation_batches = test_dataset.batch(BATCH_SIZE)\n",
    "test_batches = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T16:07:50.918022Z",
     "iopub.status.busy": "2023-06-29T16:07:50.917473Z",
     "iopub.status.idle": "2023-06-29T16:07:51.735029Z",
     "shell.execute_reply": "2023-06-29T16:07:51.734061Z",
     "shell.execute_reply.started": "2023-06-29T16:07:50.917987Z"
    }
   },
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "def double_conv_block(x, n_filters):\n",
    "\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    # Conv2D then ReLU activation\n",
    "    x = layers.Conv2D(n_filters, 3, padding = \"same\", kernel_initializer = \"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "    # dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def downsample_block(x, n_filters):\n",
    "    f = double_conv_block(x, n_filters)\n",
    "    p = layers.MaxPool2D(2)(f)\n",
    "    p = layers.Dropout(0.3)(p)\n",
    "\n",
    "    return f, p\n",
    "\n",
    "def upsample_block(x, conv_features, n_filters):\n",
    "    # upsample\n",
    "    x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
    "    # concatenate \n",
    "    x = layers.concatenate([x, conv_features])\n",
    "    # dropout\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    # Conv2D twice with ReLU activation\n",
    "    x = double_conv_block(x, n_filters)\n",
    "\n",
    "    return x\n",
    "    \n",
    "def build_unet_model():\n",
    "\n",
    "    # inputs\n",
    "    inputs = layers.Input(shape=(256,256,3))\n",
    "\n",
    "    # encoder: contracting path - downsample\n",
    "    # 1 - downsample\n",
    "    f1, p1 = downsample_block(inputs, 64)\n",
    "    # 2 - downsample\n",
    "    f2, p2 = downsample_block(p1, 128)\n",
    "    # 3 - downsample\n",
    "    f3, p3 = downsample_block(p2, 256)\n",
    "    # 4 - downsample\n",
    "    f4, p4 = downsample_block(p3, 512)\n",
    "\n",
    "    # 5 - bottleneck\n",
    "    bottleneck = double_conv_block(p4, 1024)\n",
    "    bottleneck = layers.Dropout(0.3)(bottleneck)\n",
    "\n",
    "    # decoder: expanding path - upsample\n",
    "    # 6 - upsample\n",
    "    u6 = upsample_block(bottleneck, f4, 512)\n",
    "    # 7 - upsample\n",
    "    u7 = upsample_block(u6, f3, 256)\n",
    "    # 8 - upsample\n",
    "    u8 = upsample_block(u7, f2, 128)\n",
    "    # 9 - upsample\n",
    "    u9 = upsample_block(u8, f1, 64)\n",
    "\n",
    "    # outputs\n",
    "    outputs = layers.Conv2D(1, 1, padding=\"same\", activation = \"sigmoid\")(u9)\n",
    "\n",
    "    # unet model with Keras Functional API\n",
    "    unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
    "\n",
    "    return unet_model\n",
    "\n",
    "def dice_coeff(y_true, y_pred):\n",
    "    smooth = 1.\n",
    "    # Flatten\n",
    "    y_true_f = tf.reshape(y_true, [-1])\n",
    "    y_pred_f = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
    "    score = (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
    "    return score\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    loss = 1 - dice_coeff(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "def bce_dice_loss(y_true, y_pred):\n",
    "    loss = tf.keras.losses.binary_focal_crossentropy(y_true, y_pred) + dice_loss(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "unet_model = build_unet_model()\n",
    "\n",
    "#loss = keras.losses.sparse_categorical_crossentropy()\n",
    "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                   loss=bce_dice_loss,\n",
    "                   metrics=[dice_loss, f1_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T16:08:08.872228Z",
     "iopub.status.busy": "2023-06-29T16:08:08.871857Z",
     "iopub.status.idle": "2023-06-29T16:08:29.690717Z",
     "shell.execute_reply": "2023-06-29T16:08:29.688948Z",
     "shell.execute_reply.started": "2023-06-29T16:08:08.872200Z"
    }
   },
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "\n",
    "STEPS_PER_EPOCH = total_samples // BATCH_SIZE\n",
    "\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = test_size // BATCH_SIZE // VAL_SUBSPLITS\n",
    "\n",
    "model_history = unet_model.fit(train_batches,\n",
    "                               epochs=NUM_EPOCHS,\n",
    "                               steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                               validation_steps=VALIDATION_STEPS,\n",
    "                               validation_data=validation_batches,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-29T16:06:44.556877Z",
     "iopub.status.busy": "2023-06-29T16:06:44.556471Z",
     "iopub.status.idle": "2023-06-29T16:06:45.619496Z",
     "shell.execute_reply": "2023-06-29T16:06:45.618355Z",
     "shell.execute_reply.started": "2023-06-29T16:06:44.556846Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(model_history.history[\"loss\"]) + 1)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, model_history.history[\"loss\"], \"bo\", label=\"Training loss\")\n",
    "plt.plot(epochs, model_history.history[\"val_loss\"], \"b\", label=\"Validation loss\")\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, model_history.history[\"dice_loss\"], \"bo\", label=\"Training dice_loss\")\n",
    "plt.plot(epochs, model_history.history[\"val_dice_loss\"], \"b\", label=\"Validation dice_loss\")\n",
    "plt.title(\"Training and validation dice_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, model_history.history[\"f1_m\"], \"bo\", label=\"Training f1_m\")\n",
    "plt.plot(epochs, model_history.history[\"val_f1_m\"], \"b\", label=\"Validation f1_m\")\n",
    "plt.title(\"Training and validation f1_m\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Visualization of predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask, threshold=0.2):\n",
    "  pred_mask = tf.cast(pred_mask, dtype=tf.float32)  # convertir a float\n",
    "  pred_mask = tf.where(pred_mask > threshold, 1.0, 0.0)  # usar float para el threshold\n",
    "  return pred_mask[0]\n",
    "\n",
    "def show_predictions(dataset, model, num):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_batches, unet_model, 16)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
